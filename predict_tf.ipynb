{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4embtkV0pNxM"
   },
   "source": [
    "Digits Recognition\n",
    "=============\n",
    "\n",
    "We use Tensor Flow on MNIST data. Thanks to <a href=\"https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/udacity\">Google's Udacity course</a> for demonstrating how to use neural networks in Tensor Flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "tm2CQN_Cpwj0"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import clock\n",
    "\n",
    "# Force matplotlib to not use any Xwindows backend.\n",
    "# import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 42000 train entries in 4 seconds.\n",
      "Loaded 28000 test entries in 2 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Read training data\n",
    "start = clock()\n",
    "\n",
    "train_frame = pd.read_csv('data/train.csv')\n",
    "\n",
    "# Make random train and validation sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "train_frame, valid_frame = train_test_split(train_frame, test_size = 0.2)\n",
    "\n",
    "train_labels = train_frame['label'].values\n",
    "train_dataset = train_frame.iloc[:,1:].values\n",
    "\n",
    "valid_labels = valid_frame['label'].values\n",
    "valid_dataset = valid_frame.iloc[:,1:].values\n",
    "\n",
    "print('Loaded {:d} train entries in {:.0f} seconds.'.format(\n",
    "        len(train_dataset) + len(valid_dataset), clock() - start))\n",
    "\n",
    "# Read test data \n",
    "start = clock()\n",
    "\n",
    "test_frame = pd.read_csv('data/test.csv')\n",
    "test_dataset = test_frame.values\n",
    "\n",
    "print('Loaded {:d} test entries in {:.0f} seconds.'.format(\n",
    "        len(test_dataset), clock() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L7aHrm6nGDMB"
   },
   "source": [
    "Reformat into a TensorFlow-friendly shape:\n",
    "- convolutions need the image data formatted as a cube (width by height by #channels)\n",
    "- labels as float 1-hot encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 11952,
     "status": "ok",
     "timestamp": 1446658914857,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "IRSyYiIIGIzS",
    "outputId": "650a208c-8359-4852-f4f5-8bf10e80ef6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (33600, 28, 28, 1) (33600, 10)\n",
      "Validation set (8400, 28, 28, 1) (8400, 10)\n",
      "Test set (28000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "num_labels = 10\n",
    "num_channels = 1 # grayscale\n",
    "\n",
    "def reformat(dataset, labels = None):\n",
    "  dataset = dataset.reshape(\n",
    "    (-1, image_size, image_size, num_channels)).astype(np.float32)\n",
    "  if labels is not None:\n",
    "      labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "      return dataset, labels\n",
    "  else:\n",
    "      return dataset\n",
    "\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset = reformat(test_dataset)\n",
    "\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "AgQDIREv02p1"
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5rhgjmROXu2O"
   },
   "source": [
    "Let's build a small network with two convolutional layers, followed by one fully connected layer. Convolutional networks are more expensive computationally, so we'll limit its depth and number of fully connected nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "IZYv70SvvOan"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "patch_size = 5\n",
    "depth = 16\n",
    "num_hidden = 64\n",
    "learning_rate = 0.00001\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  tf_train_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  layer1_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
    "  layer1_biases = tf.Variable(tf.zeros([depth]))\n",
    "  layer2_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, depth, depth], stddev=0.1))\n",
    "  layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
    "  layer3_weights = tf.Variable(tf.truncated_normal(\n",
    "      [image_size // 4 * image_size // 4 * depth, num_hidden], stddev=0.1))\n",
    "  layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "  layer4_weights = tf.Variable(tf.truncated_normal(\n",
    "      [num_hidden, num_labels], stddev=0.1))\n",
    "  layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "  \n",
    "  # Model.\n",
    "  def model(data):\n",
    "    conv = tf.nn.conv2d(data, layer1_weights, [1, 2, 2, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layer1_biases)\n",
    "    conv = tf.nn.conv2d(hidden, layer2_weights, [1, 2, 2, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layer2_biases)\n",
    "    shape = hidden.get_shape().as_list()\n",
    "    reshape = tf.reshape(hidden, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "    hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
    "    return tf.matmul(hidden, layer4_weights) + layer4_biases\n",
    "  \n",
    "  # Training computation.\n",
    "  logits = model(tf_train_dataset)\n",
    "  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "    \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
    "  test_prediction = tf.nn.softmax(model(tf_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_steps = 1001\n",
    "\n",
    "start = clock()\n",
    "loss_epoch = {}\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    \n",
    "    if (step % 50 == 0):      \n",
    "      # Collect loss vs epochs for plotting\n",
    "      epoch = batch_size * step / train_labels.shape[0]\n",
    "      loss_epoch[epoch] = l\n",
    "            \n",
    "      print('Minibatch loss at step %d: %f' % (step, l))\n",
    "      print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "      print('Validation accuracy: %.1f%%' % accuracy(valid_prediction.eval(), valid_labels))\n",
    "  \n",
    "  # print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))\n",
    "\n",
    "  # Save predictions\n",
    "  test_frame['ImageId'] = range(1, len(test_dataset)+1)\n",
    "  test_frame['Label'] = np.argmax(test_prediction.eval(), 1)\n",
    "  test_frame.to_csv('predict.csv', cols = ('ImageId', 'Label'), index = None)\n",
    "\n",
    "# Print elapsed time\n",
    "print('Elapsed time: {:.0f} seconds.'.format(clock() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/matplotlib/collections.py:549: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self._edgecolors == 'face':\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfgAAAEKCAYAAAD+ckdtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nP6zivlNxoYV+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4b9c8a6860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make  loss function against epoch plot\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.scatter(list(loss_epoch.keys()), list(loss_epoch.values()))\n",
    "plt.yscale('log')\n",
    "plt.ylabel('Minibatch loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.axis('tight')\n",
    "\n",
    "# Save and display figure\n",
    "plt.savefig('loss.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "4_convolutions.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
