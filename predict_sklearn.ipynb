{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Kaggle Digit Recognition\n",
      "\n",
      "This is one of the problem proposed on Kaggle: handwritten digit recognition using the MNIST data. We use scikit-learn."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "from time import clock"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We begin by loading the both the training and the testing data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Read training data\n",
      "start = clock()\n",
      "\n",
      "train_frame = pd.read_csv('data/train.csv')\n",
      "label = train_frame['label'].values\n",
      "train = train_frame.iloc[:,1:].values\n",
      "# train = train.reshape(-1,28,28)\n",
      "\n",
      "print('Loaded {:d} train entries in {:.0f} seconds.'.format(len(train), clock() - start))\n",
      "\n",
      "# Train on fewer entries\n",
      "# label = label[0::10]\n",
      "# train = train[0::10]\n",
      "\n",
      "# Read test data \n",
      "start = clock()\n",
      "\n",
      "test_frame = pd.read_csv('data/test.csv')\n",
      "test = test_frame.values\n",
      "# test = test.reshape(-1,28,28)\n",
      "\n",
      "print('Loaded {:d} test entries in {:.0f} seconds.'.format(len(test), clock() - start))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To make sure that we load the data correctly, we can take a random digit in the training set to visualize."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Select a random entry\n",
      "\n",
      "from random import randint  \n",
      "\n",
      "i = randint(0,len(train)-1)\n",
      "print(\"Displayed train entry {:d} labelled {:d}.\".format(i, label[i]))\n",
      "\n",
      "# Plot using matplotlib\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.cm as cm\n",
      "%matplotlib inline  \n",
      "    \n",
      "train_square = train.reshape(-1,28,28)\n",
      "plt.imshow(train_square[i], cmap=cm.binary)\n",
      "plt.axis('off')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Random Forest\n",
      "\n",
      "A first demonstration can be quickly done with a random forest."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "clf = RandomForestClassifier(n_estimators = 100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## PCA + SVC\n",
      "\n",
      "Scikit-learn provides various preprocessor for the data, like PCA. We can then combine this with a SVC in a pipeline."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.decomposition import PCA\n",
      "from sklearn.svm import SVC\n",
      "\n",
      "# from sklearn.preprocessing import StandardScaler\n",
      "# train = StandardScaler().fit_transform(train)\n",
      "\n",
      "pca = PCA(n_components = 35, whiten = True)\n",
      "clf = Pipeline([('PCA', pca), ('SVC', SVC())])\n",
      "\n",
      "# from sklearn.svm import LinearSVC\n",
      "# clf = LinearSVC(tol = 0.01, C = 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can also use PCA directly."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "start = clock()\n",
      "\n",
      "pca.fit(train)\n",
      "train_transformed = pca.transform(train)\n",
      "test_transformed = pca.transform(test)\n",
      "\n",
      "print(\"Transformed data in {:.0f} seconds using {:d} components explaining {:.0%} of the variance.\".format(\n",
      "        clock() - start, n_comp, sum(pca.explained_variance_ratio_)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Validating, Training, Extrapolating\n",
      "We can use cross-validation to get an idea of how well the classifier generalizes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import cross_val_score\n",
      "start = clock()\n",
      "\n",
      "scores = cross_val_score(clf, train, label)\n",
      "\n",
      "print(\"Performed {:d}-fold cross validation in {:.0f} seconds with accuracy {:0.4f} +/- {:0.4f}.\".format(\n",
      "    len(scores), clock() - start, scores.mean(), scores.std()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We are now ready to fit the classifier to the training data, predict/extrapolate to the test data, and save the results."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Fit training data\n",
      "\n",
      "start = clock()\n",
      "clf.fit(train, label)\n",
      "print(\"Fitted training data in {:.0f} seconds.\".format(clock() - start))\n",
      "\n",
      "# Extrapolate to test data\n",
      "\n",
      "start = clock()\n",
      "predict = clf.predict(test)\n",
      "print(\"Extrapolated to test data in {:.0f} seconds.\".format(clock() - start))\n",
      "\n",
      "# Save results\n",
      "\n",
      "test_frame['ImageId'] = range(1,len(test)+1)\n",
      "test_frame['Label'] = predict\n",
      "test_frame.to_csv('predict.csv', cols = ('ImageId', 'Label'), index = None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Improvements\n",
      "We can attempt to select the classifier's parameters by optimizing with grid search."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.grid_search import GridSearchCV\n",
      "\n",
      "# Parameter space to search for SVC\n",
      "import numpy as np\n",
      "params = [{'C': np.logspace(-1, 3), 'gamma': np.logspace(-4, -1)}]\n",
      "\n",
      "# Search on fewer entries\n",
      "label_few = label[0::10]\n",
      "train_few = train[0::10]\n",
      "    \n",
      "# Run exhaustive grid search\n",
      "start = clock()\n",
      "\n",
      "gs = GridSearchCV(estimator = clf, param_grid = params, n_jobs = 2)\n",
      "gs.fit(train_few, label_few)\n",
      "\n",
      "print(\"Parameter optimized {} yielding {:.4f} in {:.0f} seconds.\".format(\n",
      "        gs.best_params_, gs.best_score_, clock() - start))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# from sklearn.linear_model import SGDClassifier\n",
      "# clf = SGDClassifier()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Tensor Flow\n",
      "Google released Tensor Flow, and an accompanying scikit-learn-like interface called Scikit Flow. This supports basic neural networks. Note: at this point, grid_seach below is not compatible."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Classifiers from Scikit Flow\n",
      "\n",
      "# Scikit Flow has the following choices of optimizer: SGD, Adam, Adagrad\n",
      "\n",
      "# from skflow import TensorFlowLinearClassifier\n",
      "# clf = TensorFlowLinearClassifier(n_classes = 10, \n",
      "                                # batch_size = 256, steps = 1400, learning_rate = 0.01, optimizer = 'Adagrad')\n",
      "\n",
      "# from skflow import TensorFlowLinearRegressor\n",
      "# clf = TensorFlowLinearRegressor(n_classes = 10, \n",
      "                                # batch_size = 256, steps = 1400, learning_rate = 0.01, optimizer = 'Adagrad')\n",
      "\n",
      "# from skflow import TensorFlowDNNClassifier\n",
      "clf = TensorFlowDNNClassifier(hidden_units = [100, 200, 200, 200, 100],\n",
      "                              n_classes = 10, batch_size = 256, steps = 1000, learning_rate = 0.01, optimizer = 'Adagrad')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Scikit-learn also has neural networks available."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# MLPClassifier requires 0.18dev+ and is not available in 0.17\n",
      "from sklearn.neural_network import MLPClassifier\n",
      "clf = MLPClassifier(algorithm = 'l-bfgs', alpha = 1e-5, hidden_layer_sizes = (5, 2), random_state = 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}