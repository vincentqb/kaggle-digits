{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Digit Recognition\n",
    "\n",
    "This is one of the problem proposed on Kaggle: handwritten digit recognition using the MNIST data. We use scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from time import clock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by loading the both the training and the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read training data\n",
    "start = clock()\n",
    "\n",
    "train_frame = pd.read_csv('data/train.csv')\n",
    "label = train_frame['label'].values\n",
    "train = train_frame.iloc[:,1:].values\n",
    "\n",
    "print('Loaded {:d} train entries in {:.0f} seconds.'.format(len(train), clock() - start))\n",
    "\n",
    "# Train on fewer entries\n",
    "# label = label[0::10]\n",
    "# train = train[0::10]\n",
    "\n",
    "# Read test data \n",
    "start = clock()\n",
    "\n",
    "test_frame = pd.read_csv('data/test.csv')\n",
    "test = test_frame.values\n",
    "\n",
    "print('Loaded {:d} test entries in {:.0f} seconds.'.format(len(test), clock() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure that we load the data correctly, we can take a random digit in the training set to visualize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select a random entry\n",
    "\n",
    "from random import randint  \n",
    "\n",
    "i = randint(0,len(train)-1)\n",
    "print(\"Displayed train entry {:d} labelled {:d}.\".format(i, label[i]))\n",
    "\n",
    "# Plot using matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline  \n",
    "    \n",
    "train_square = train.reshape(-1,28,28)\n",
    "plt.imshow(train_square[i], cmap=cm.binary)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Classifier\n",
    "\n",
    "A first demonstration can be quickly done with a random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "clf = ExtraTreesClassifier(n_estimators = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another choice is to first preprocess the data with PCA, say, and then pipeline this with SVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "pca = PCA(n_components = 35, whiten = True)\n",
    "clf = make_pipeline(pca, SVC())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate, Train, Extrapolate\n",
    "We can use cross-validation to get an idea of how well the classifier generalizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "start = clock()\n",
    "\n",
    "scores = cross_val_score(clf, train, label)\n",
    "\n",
    "print(\"Performed {:d}-fold cross validation in {:.0f} seconds with accuracy {:0.4f} +/- {:0.4f}.\".format(\n",
    "    len(scores), clock() - start, scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result\n",
    "- Random Forest with 1000 estimator performed 3-fold cross validation in 655 seconds with accuracy 0.9645 +/- 0.0022. \n",
    "- ExtraTrees performed 3-fold cross validation in 49 seconds with accuracy 0.9656 +/- 0.0006.\n",
    "- PCA+SVM performed 3-fold cross validation in 132 seconds with accuracy 0.9777 +/- 0.0013."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to fit the classifier to the training data, predict/extrapolate to the test data, and save the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit training data\n",
    "\n",
    "start = clock()\n",
    "clf.fit(train, label)\n",
    "print(\"Fitted training data in {:.0f} seconds.\".format(clock() - start))\n",
    "\n",
    "# Extrapolate to test data\n",
    "\n",
    "start = clock()\n",
    "predict = clf.predict(test)\n",
    "print(\"Extrapolated to test data in {:.0f} seconds.\".format(clock() - start))\n",
    "\n",
    "# Save results\n",
    "\n",
    "test_frame['ImageId'] = range(1,len(test)+1)\n",
    "test_frame['Label'] = predict\n",
    "test_frame.to_csv('predict.csv', cols = ('ImageId', 'Label'), index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we used PCA+SVC, PCA can tell us how much of the variance is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "variance = sum(clf.named_steps['PCA'].pca.explained_variance_ratio_)\n",
    "print(\"PCA uses {:d} components explaining {:.0%} of the variance.\".format(n_comp, variance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvements\n",
    "We can attempt to select SVC's parameters by optimizing with grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Transform data\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "n_comp = 35\n",
    "pca = PCA(n_components = n_comp, whiten = True)\n",
    "\n",
    "start = clock()\n",
    "pca.fit(train)\n",
    "train_transformed = pca.transform(train)\n",
    "\n",
    "print(\"Transformed data in {:.0f} seconds using {:d} components explaining {:.0%} of the variance.\".format(\n",
    "        clock() - start, n_comp, sum(pca.explained_variance_ratio_)))\n",
    "\n",
    "# Select classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "algo = 'rbf'\n",
    "tol = 0.01\n",
    "clf = SVC(kernel = algo, tol = tol, shrinking = True)\n",
    "\n",
    "# Search on fewer entries\n",
    "label_few = label[0::10]\n",
    "train_few = train_transformed[0::10]\n",
    "\n",
    "# Parameter space to search for SVC\n",
    "from numpy import logspace\n",
    "params = [{'C': logspace(-1, 3), 'gamma': logspace(-4, -1)}]\n",
    "    \n",
    "# Run exhaustive grid search\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "start = clock()\n",
    "\n",
    "gs = GridSearchCV(estimator = clf, param_grid = params, n_jobs = 2)\n",
    "gs.fit(train_few, label_few)\n",
    "\n",
    "print(\"Parameter optimi zed {} yielding {:.4f} in {:.0f} seconds.\".format(\n",
    "        gs.best_params_, gs.best_score_, clock() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some choices of parameters for SVC that seem to work reasonably well.\n",
    "- C = 4.2919342601287758 and gamma = 0.028117686979742307 gives 0.8857 in 6 seconds.\n",
    "- C = 1.3894954943731375 and gamma = 0.042919342601287783 gives 0.9502 in 27 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn also has neural networks available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MLPClassifier requires 0.18dev+ and is not available in 0.17\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(algorithm = 'l-bfgs', alpha = 1e-5, hidden_layer_sizes = (5, 2), random_state = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
